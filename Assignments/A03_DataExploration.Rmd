---
title: "Assignment 3: Data Exploration"
author: "Ying Wei Jong"
output: pdf_document
geometry: margin=2.54cm
---

## OVERVIEW

This exercise accompanies the lessons in Environmental Data Analytics (ENV872L) on data exploration. 

## Directions
1. Change "Student Name" on line 3 (above) with your name.
2. Use the lesson as a guide. It contains code that can be modified to complete the assignment.
3. Work through the steps, **creating code and output** that fulfill each instruction.
4. Be sure to **answer the questions** in this assignment document.
Space for your answers is provided in this document and is indicated by the ">" character.
If you need a second paragraph be sure to start the first line with ">".
You should notice that the answer is highlighted in green by RStudio. 
6. When you have completed the assignment, **Knit** the text and code into a single PDF file.
You will need to have the correct software installed to do this (see Software Installation Guide)
Press the `Knit` button in the RStudio scripting panel.
This will save the PDF output in your Assignments folder.
8. After Knitting, please submit the completed exercise (PDF file) to the dropbox in Sakai. Please add your last name into the file name (e.g., "Salk_A02_DataExploration.pdf") prior to submission.

The completed exercise is due on Thursday, 31 January, 2019 before class begins.

## 1) Set up your R session

Check your working directory, load necessary packages (tidyverse), and upload the North Temperate Lakes long term monitoring dataset for the light, temperature, and oxygen data for three lakes (file name: NTL-LTER_Lake_ChemistryPhysics_Raw.csv). Type your code into the R chunk below.
```{r}
setwd("/Users/YwJong/Documents/NSOE/Spring 2019/ENV 872 Environment Data Analytics/Labs")
library(tidyverse)
LTER <- read.csv("/Users/YwJong/Documents/NSOE/Spring 2019/ENV 872 Environment Data Analytics/Labs/Data/Raw/NTL-LTER_Lake_ChemistryPhysics_Raw.csv")


```

## 2) Learn about your system

Read about your dataset in the NTL-LTER README file. What are three salient pieces of information you gained from reading this file?

> ANSWER: The LTER data was divided into three different csvs. One focuses on the Carbon content, one on Nutrient content and another on physical and chemical limnology properties of Lakes at Cascade Project at North Temperate Lakes. We are looking at the csv that has physical and chemical limnology properties. This csv contains information of physical and chemical readings at various depths measured using methods described by Carpenter & Kitchell (1993) and Carpenter et al (2001). 

## 3) Obtain basic summaries of your data

Write R commands to display the following information: 

1. dimensions of the dataset
2. class of the dataset
3. first 8 rows of the dataset
4. class of the variables lakename, sampledate, depth, and temperature
5. summary of lakename, depth, and temperature

```{r}
# 1 display dismensions of the dataset
dim(LTER)
# 2 class of the dataset
class(LTER)
# 3
head(LTER,8)
# 4
str(LTER)
# 5
summary(LTER$lakename)
summary(LTER$depth)
summary(LTER$temperature_C)
```

Change sampledate to class = date. After doing this, write an R command to display that the class of sammpledate is indeed date. Write another R command to show the first 10 rows of the date column. 

```{r}
#Change sampledate to class=date
LTER$sampledate <- as.Date(LTER$sampledate, format = "%m/%d/%y")
#Display class of LTER$sampledate
str(LTER)
#first 10 rows of date column
head(LTER$sampledate, 10)
```

Question: Do you want to remove NAs from this dataset? Why or why not?

> ANSWER: I tend not to remove NAs until I absolutely have to. For example, I might keep all the NAs in temperature until when I run a regression and the model does not accept any NAs. I will also keep all the NAs unless the NA was in a column so critical in analysis that the data point was unusable anyway.


## 4) Explore your data graphically

Write R commands to display graphs depicting: 

1. Bar chart of temperature counts for each lake
2. Histogram of count distributions of temperature (all temp measurements together)
3. Change histogram from 2 to have a different number or width of bins
4. Frequency polygon of temperature for each lake. Choose different colors for each lake.
5. Boxplot of temperature for each lake
6. Boxplot of temperature based on depth, with depth divided into 0.25 m increments
7. Scatterplot of temperature by depth

```{r, fig.height = 3, fig.width = 4}
# 1 Bar chart of temperature counts for each lake. I personally don't think this is the best way to display the data. position dodge seems to work better, but there are too many geoms here to display them properly
ggplot(LTER) +
  geom_bar(aes(x=temperature_C, color=lakename), position = "stack")

# 2 Histogram of count distributions of temperature (all temp measurements together)
ggplot(LTER) +
  geom_histogram(aes(x=temperature_C), binwidth = 0.1)
 
# 3 Histogram of count distributions of temperature with lower number of bins, i.e. lower resolution
ggplot(LTER) +
  geom_histogram(aes(x=temperature_C), bins = 15)

# 4 Frequency polygon of temperature for each lake. Different colors for each lake.
ggplot(LTER) +
  geom_freqpoly(aes(x=temperature_C, color=lakename))

# 5 Boxplot of temperature for each lake
ggplot(LTER) +
  geom_boxplot(aes(x = lakename, y = temperature_C))

# 6 Boxplot of temperature based on depth, with depth divided into 0.25 m increments
ggplot(LTER) +
  geom_boxplot(aes(x = depth, y = temperature_C, group=cut_width(depth, 0.25)))

# 7 Scatterplot of temperature by depth
ggplot(LTER) +
  geom_point(aes(x=depth, y=temperature_C, color=lakename))

```
## 5) Form questions for further data analysis

What did you find out about your data from the basic summaries and graphs you made? Describe in 4-6 sentences.

> ANSWER: Some lakes are more represented than others in this dataset (i.e. some lakes have more data than others). Each lake has different median temperature. Most temperatures observations were about 4 celsius degrees. The deeper the lake depth, the lower the temperature.

What are 3 further questions you might ask as you move forward with analysis of this dataset?

> ANSWER 1: How does the average temperature change throughout the years?

> ANSWER 2: How do the dissolved oxygen and irradiance reading change with lake depth?

> ANSWER 3: Are there any correlation between depth and dissolved oxygen (and between pairs of other variables)?
